{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778f5f0-a08a-4ce0-ac02-c1c663476e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training code\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import warnings\n",
    "from glob import glob\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Custom Dataset with Augmented Images and Oversampling\n",
    "class ODIRDataset(Dataset):\n",
    "    def __init__(self, excel_file, img_dir, aug_dir, transform=None, oversample_factor=2):\n",
    "        self.data = pd.read_excel(excel_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.aug_dir = aug_dir\n",
    "        self.transform = transform\n",
    "        self.label_columns = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "        self.oversample_factor = oversample_factor\n",
    "        \n",
    "        # Calculate class weights\n",
    "        class_counts = self.data[self.label_columns].sum()\n",
    "        total_samples = len(self.data)\n",
    "        class_weights = total_samples / (len(self.label_columns) * class_counts)\n",
    "        self.class_weights = torch.FloatTensor(class_weights.values).to(device)\n",
    "        \n",
    "        print(f\"Class distribution: {class_counts.to_dict()}\")\n",
    "        print(f\"Class weights: {class_weights.to_dict()}\")\n",
    "\n",
    "        # Load images and labels\n",
    "        self.image_pairs = []\n",
    "        self.labels = []\n",
    "        self.demographics = []\n",
    "        \n",
    "        # Add original image pairs\n",
    "        for idx in range(len(self.data)):\n",
    "            row = self.data.iloc[idx]\n",
    "            left_img_path = os.path.join(self.img_dir, row['Left-Fundus'])\n",
    "            right_img_path = os.path.join(self.img_dir, row['Right-Fundus'])\n",
    "            if os.path.exists(left_img_path) and os.path.exists(right_img_path):\n",
    "                self.image_pairs.append((left_img_path, right_img_path))\n",
    "                self.labels.append(torch.FloatTensor(row[self.label_columns].values.astype(float)))\n",
    "                gender = 1 if row['Patient Sex'] == 'Male' else 0\n",
    "                age = row['Patient Age'] / 100.0\n",
    "                self.demographics.append(torch.tensor([age, gender], dtype=torch.float32))\n",
    "\n",
    "        # Add augmented images with oversampling for minority classes\n",
    "        aug_images = glob(os.path.join(self.aug_dir, \"left_*.png\"))\n",
    "        for aug_img in aug_images:\n",
    "            filename = os.path.basename(aug_img)\n",
    "            try:\n",
    "                id_str = filename.split('_')[1].split('.')[0]\n",
    "                id_num = int(id_str)\n",
    "                row = self.data[self.data['ID'] == id_num]\n",
    "                if len(row) == 0:\n",
    "                    continue\n",
    "                row = row.iloc[0]\n",
    "                orig_left = os.path.join(self.img_dir, row['Left-Fundus'])\n",
    "                orig_right = os.path.join(self.img_dir, row['Right-Fundus'])\n",
    "                labels = torch.FloatTensor(row[self.label_columns].values.astype(float))\n",
    "                gender = 1 if row['Patient Sex'] == 'Male' else 0\n",
    "                age = row['Patient Age'] / 100.0\n",
    "                demo = torch.tensor([age, gender], dtype=torch.float32)\n",
    "\n",
    "                # Oversample minority classes (A, H, D)\n",
    "                oversample = 1\n",
    "                if labels[4] == 1 or labels[5] == 1 or labels[1] == 1:  # A, H, D\n",
    "                    oversample = self.oversample_factor\n",
    "\n",
    "                for _ in range(oversample):\n",
    "                    self.image_pairs.append((aug_img, orig_right))\n",
    "                    self.labels.append(labels)\n",
    "                    self.demographics.append(demo)\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "\n",
    "        print(f\"Total image pairs (original + augmented): {len(self.image_pairs)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            left_img_path, right_img_path = self.image_pairs[idx]\n",
    "            left_img = np.array(Image.open(left_img_path).convert('RGB'))\n",
    "            right_img = np.array(Image.open(right_img_path).convert('RGB'))\n",
    "            \n",
    "            if self.transform:\n",
    "                left_img = self.transform(image=left_img)['image']\n",
    "                right_img = self.transform(image=right_img)['image']\n",
    "            \n",
    "            return left_img, right_img, self.demographics[idx], self.labels[idx]\n",
    "        except Exception as e:\n",
    "            print(f\"Error at index {idx}: {e}\")\n",
    "            return None\n",
    "\n",
    "# Data transforms with more aggressive augmentation for minority classes\n",
    "data_transforms = {\n",
    "    'train': A.Compose([\n",
    "        A.Resize(256, 256),\n",
    "        A.RandomCrop(224, 224),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Rotate(limit=30, p=0.8),  # Increased rotation\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),  # More aggressive\n",
    "        A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2, p=0.7),\n",
    "        A.GaussNoise(p=0.3),  # Add noise for robustness\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    'val': A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Custom collate function to handle None values\n",
    "def custom_collate(batch):\n",
    "    batch = [x for x in batch if x is not None]\n",
    "    if not batch:\n",
    "        return None\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "# Model Definitions with Attention Mechanism\n",
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.conv(x)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention\n",
    "\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super().__init__()\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        self.backbone = nn.Sequential(*list(model.children())[:-2])  # Remove the last two layers\n",
    "        self.attention = AttentionModule(2048)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.demo_fc = nn.Sequential(nn.Linear(2, 32), nn.ReLU(), nn.Dropout(0.6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048 * 2 + 32, 512), nn.ReLU(), nn.Dropout(0.7),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, left_img, right_img, demo):\n",
    "        left_features = self.backbone(left_img)\n",
    "        right_features = self.backbone(right_img)\n",
    "        left_features = self.attention(left_features)\n",
    "        right_features = self.attention(right_features)\n",
    "        left_features = self.pool(left_features).flatten(1)\n",
    "        right_features = self.pool(right_features).flatten(1)\n",
    "        demo_features = self.demo_fc(demo)\n",
    "        combined = torch.cat((left_features, right_features, demo_features), dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "class EfficientNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super().__init__()\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        self.backbone = nn.Sequential(*list(model.children())[:-2])\n",
    "        self.attention = AttentionModule(1280)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.demo_fc = nn.Sequential(nn.Linear(2, 32), nn.ReLU(), nn.Dropout(0.6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1280 * 2 + 32, 512), nn.ReLU(), nn.Dropout(0.7),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, left_img, right_img, demo):\n",
    "        left_features = self.backbone(left_img)\n",
    "        right_features = self.backbone(right_img)\n",
    "        left_features = self.attention(left_features)\n",
    "        right_features = self.attention(right_features)\n",
    "        left_features = self.pool(left_features).flatten(1)\n",
    "        right_features = self.pool(right_features).flatten(1)\n",
    "        demo_features = self.demo_fc(demo)\n",
    "        combined = torch.cat((left_features, right_features, demo_features), dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "class DenseNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super().__init__()\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        self.backbone = nn.Sequential(*list(model.children())[:-1])\n",
    "        self.attention = AttentionModule(1024)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.demo_fc = nn.Sequential(nn.Linear(2, 32), nn.ReLU(), nn.Dropout(0.6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024 * 2 + 32, 512), nn.ReLU(), nn.Dropout(0.7),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, left_img, right_img, demo):\n",
    "        left_features = self.backbone(left_img)\n",
    "        right_features = self.backbone(right_img)\n",
    "        left_features = self.attention(left_features)\n",
    "        right_features = self.attention(right_features)\n",
    "        left_features = self.pool(left_features).flatten(1)\n",
    "        right_features = self.pool(right_features).flatten(1)\n",
    "        demo_features = self.demo_fc(demo)\n",
    "        combined = torch.cat((left_features, right_features, demo_features), dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "# Focal Loss with Adjusted Class Weights\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = (1 - pt) ** self.gamma * BCE_loss\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[targets.long()]\n",
    "            F_loss = alpha_t * F_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return F_loss.mean()\n",
    "        return F_loss\n",
    "\n",
    "# Optimize Thresholds with Class-Specific Ranges\n",
    "def optimize_thresholds(outputs, targets):\n",
    "    outputs_np = torch.sigmoid(outputs).cpu().numpy()\n",
    "    targets_np = targets.cpu().numpy()\n",
    "    best_thresholds = []\n",
    "    \n",
    "    for class_idx in range(targets_np.shape[1]):\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5\n",
    "        # Adjust threshold range based on class performance\n",
    "        if class_idx in [1, 4, 5]:  # D, A, H (low precision, high recall)\n",
    "            threshold_range = np.arange(0.5, 0.9, 0.05)  # Higher thresholds to improve precision\n",
    "        else:\n",
    "            threshold_range = np.arange(0.3, 0.7, 0.05)\n",
    "        for threshold in threshold_range:\n",
    "            preds = (outputs_np[:, class_idx] >= threshold).astype(targets_np.dtype)\n",
    "            f1 = f1_score(targets_np[:, class_idx], preds, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        best_thresholds.append(best_threshold)\n",
    "    \n",
    "    return best_thresholds\n",
    "\n",
    "# Metrics Calculation with Confusion Matrix\n",
    "def calculate_metrics(outputs, targets, thresholds=None, class_names=None, phase='val'):\n",
    "    outputs_np = torch.sigmoid(outputs).cpu().numpy()\n",
    "    targets_np = targets.cpu().numpy()\n",
    "    \n",
    "    if thresholds is None:\n",
    "        thresholds = [0.5] * targets_np.shape[1]\n",
    "    \n",
    "    preds = np.zeros_like(outputs_np, dtype=targets_np.dtype)\n",
    "    for i in range(len(thresholds)):\n",
    "        preds[:, i] = (outputs_np[:, i] >= thresholds[i]).astype(targets_np.dtype)\n",
    "    \n",
    "    precision = precision_score(targets_np, preds, average=None, zero_division=0)\n",
    "    recall = recall_score(targets_np, preds, average=None, zero_division=0)\n",
    "    f1 = f1_score(targets_np, preds, average=None, zero_division=0)\n",
    "    accuracy = [accuracy_score(targets_np[:, i], preds[:, i]) for i in range(targets_np.shape[1])]\n",
    "    \n",
    "    # Confusion matrix for validation phase\n",
    "    if phase == 'val':\n",
    "        for i, name in enumerate(class_names):\n",
    "            cm = confusion_matrix(targets_np[:, i], preds[:, i])\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f'Confusion Matrix for Class {name}')\n",
    "            plt.ylabel('True')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.savefig(f'confusion_matrix_{name}.png')\n",
    "            plt.close()\n",
    "    \n",
    "    return {\n",
    "        'macro_precision': np.mean(precision),\n",
    "        'macro_recall': np.mean(recall),\n",
    "        'macro_f1': np.mean(f1),\n",
    "        'macro_accuracy': np.mean(accuracy),\n",
    "        'per_class_precision': precision,\n",
    "        'per_class_recall': recall,\n",
    "        'per_class_f1': f1,\n",
    "        'per_class_accuracy': accuracy,\n",
    "        'thresholds': thresholds\n",
    "    }\n",
    "\n",
    "# Training Function with Improved Early Stopping\n",
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=15, model_name=\"model\", patience=2):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_macro_f1 = 0.0\n",
    "    scaler = GradScaler()\n",
    "    class_names = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "    thresholds = None\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}\\n{\"-\"*10}')\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'val' and epoch % 2 != 0:\n",
    "                continue\n",
    "            model.train() if phase == 'train' else model.eval()\n",
    "            running_loss = 0.0\n",
    "            all_outputs, all_targets = [], []\n",
    "            \n",
    "            for batch in dataloaders[phase]:\n",
    "                if batch is None:\n",
    "                    continue\n",
    "                left_imgs, right_imgs, demos, targets = [x.to(device, non_blocking=True) for x in batch]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    with autocast():\n",
    "                        outputs = model(left_imgs, right_imgs, demos)\n",
    "                        loss = criterion(outputs, targets)\n",
    "                    if phase == 'train':\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                \n",
    "                running_loss += loss.item() * left_imgs.size(0)\n",
    "                all_outputs.append(outputs.detach())\n",
    "                all_targets.append(targets)\n",
    "            \n",
    "            if not all_outputs:\n",
    "                continue\n",
    "            all_outputs = torch.cat(all_outputs)\n",
    "            all_targets = torch.cat(all_targets)\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            if phase == 'val':\n",
    "                thresholds = optimize_thresholds(all_outputs, all_targets)\n",
    "            metrics = calculate_metrics(all_outputs, all_targets, thresholds, class_names, phase)\n",
    "            \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f}')\n",
    "            print(f'{phase} Macro Precision: {metrics[\"macro_precision\"]:.4f}')\n",
    "            print(f'{phase} Macro Recall: {metrics[\"macro_recall\"]:.4f}')\n",
    "            print(f'{phase} Macro F1: {metrics[\"macro_f1\"]:.4f}')\n",
    "            print(f'{phase} Macro Accuracy: {metrics[\"macro_accuracy\"]:.4f}')\n",
    "            print(\"Per-class metrics:\")\n",
    "            for i, name in enumerate(class_names):\n",
    "                print(f\"{name}: Precision={metrics['per_class_precision'][i]:.4f}, \"\n",
    "                      f\"Recall={metrics['per_class_recall'][i]:.4f}, \"\n",
    "                      f\"F1={metrics['per_class_f1'][i]:.4f}, \"\n",
    "                      f\"Accuracy={metrics['per_class_accuracy'][i]:.4f}\")\n",
    "            if phase == 'val':\n",
    "                print(\"Optimized Thresholds:\", {name: thresh for name, thresh in zip(class_names, thresholds)})\n",
    "            \n",
    "            if phase == 'val':\n",
    "                scheduler.step(epoch_loss)\n",
    "                if metrics['macro_f1'] > best_macro_f1:\n",
    "                    best_macro_f1 = metrics['macro_f1']\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    torch.save(model.state_dict(), f'{model_name}_best.pth')\n",
    "                    print(f\"‚úÖ Saved best model (F1: {best_macro_f1:.4f})\")\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        print(\"Early stopping triggered\")\n",
    "                        break\n",
    "            \n",
    "            vram = torch.cuda.memory_allocated(device) / 1024**3\n",
    "            print(f\"VRAM Usage: {vram:.2f} GB\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            break\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f\"Epoch time: {epoch_time:.2f} seconds\\n\")\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, {\n",
    "        'macro_f1': best_macro_f1,\n",
    "        'thresholds': thresholds\n",
    "    }\n",
    "\n",
    "# Ensemble Model\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, models, weights):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        self.weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "    \n",
    "    def forward(self, left_img, right_img, demo):\n",
    "        outputs = [torch.sigmoid(model(left_img, right_img, demo)) for model in self.models]\n",
    "        outputs = torch.stack(outputs)\n",
    "        return torch.sum(outputs * self.weights[:, None, None], dim=0)\n",
    "\n",
    "# Main Execution\n",
    "def main():\n",
    "    excel_path = r\"C:\\Users\\OMEN\\Saved Programs\\Disease prediction\\fundus_disease_prediction\\dataset\\data.xlsx\"\n",
    "    img_dir = r\"C:\\Users\\OMEN\\Saved Programs\\Disease prediction\\fundus_disease_prediction\\dataset\\images\"\n",
    "    aug_dir = r\"C:\\Users\\OMEN\\Saved Programs\\Disease prediction\\fundus_disease_prediction\\dataset\\images\\augmented\"\n",
    "    \n",
    "    dataset = ODIRDataset(excel_path, img_dir, aug_dir, data_transforms['train'], oversample_factor=3)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_data, val_data = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    val_data.dataset.transform = data_transforms['val']\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(train_data, batch_size=64, shuffle=True, num_workers=0, \n",
    "                            pin_memory=True, collate_fn=custom_collate),  # Increased batch size and num_workers\n",
    "        'val': DataLoader(val_data, batch_size=64, num_workers=0, \n",
    "                          pin_memory=True, collate_fn=custom_collate)\n",
    "    }\n",
    "    \n",
    "    criterion = FocalLoss(alpha=dataset.class_weights * 1.5, gamma=2.0)  # Increased weight for minority classes\n",
    "    models_to_train = [\n",
    "        (ResNetModel, \"resnet50\"),\n",
    "        (EfficientNetModel, \"efficientnet\"),\n",
    "        (DenseNetModel, \"densenet\")\n",
    "    ]\n",
    "    \n",
    "    trained_models, metrics_list = [], []\n",
    "    for model_class, name in models_to_train:\n",
    "        print(f\"\\n===== Training {name} =====\")\n",
    "        model = model_class(num_classes=8).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-3)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
    "        model, metrics = train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=15, model_name=name, patience=2)\n",
    "        trained_models.append(model)\n",
    "        metrics_list.append(metrics)\n",
    "    \n",
    "    # Use F1-score for ensemble weights\n",
    "    weights = [m['macro_f1'] / sum(m['macro_f1'] for m in metrics_list) for m in metrics_list]\n",
    "    ensemble = EnsembleModel(trained_models, weights).to(device)\n",
    "    \n",
    "    # Evaluate Ensemble\n",
    "    ensemble.eval()\n",
    "    all_outputs, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloaders['val']:\n",
    "            if batch is None:\n",
    "                continue\n",
    "            inputs = [x.to(device, non_blocking=True) for x in batch]\n",
    "            with autocast():\n",
    "                outputs = ensemble(*inputs[:-1])\n",
    "            all_outputs.append(outputs)\n",
    "            all_targets.append(inputs[-1])\n",
    "    \n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    thresholds = optimize_thresholds(all_outputs, all_targets)\n",
    "    metrics = calculate_metrics(all_outputs, all_targets, thresholds, ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O'], phase='val')\n",
    "    print(\"\\n===== Ensemble Performance =====\")\n",
    "    print(f\"Macro Precision: {metrics['macro_precision']:.4f}\")\n",
    "    print(f\"Macro Recall: {metrics['macro_recall']:.4f}\")\n",
    "    print(f\"Macro F1: {metrics['macro_f1']:.4f}\")\n",
    "    print(f\"Macro Accuracy: {metrics['macro_accuracy']:.4f}\")\n",
    "    print(\"Per-class metrics:\")\n",
    "    for i, name in enumerate(['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']):\n",
    "        print(f\"{name}: Precision={metrics['per_class_precision'][i]:.4f}, \"\n",
    "              f\"Recall={metrics['per_class_recall'][i]:.4f}, \"\n",
    "              f\"F1={metrics['per_class_f1'][i]:.4f}, \"\n",
    "              f\"Accuracy={metrics['per_class_accuracy'][i]:.4f}\")\n",
    "    print(\"Optimized Thresholds:\", {name: thresh for name, thresh in zip(['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O'], thresholds)})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f3194f2-2b44-4e8e-9502-267c55d2a889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Running fundus image disease prediction...\n",
      "Analyzing left image: 171_left.jpg\n",
      "Analyzing right image: 171_right.jpg\n",
      "Patient: Age 60, Gender: Male\n",
      "Using device: cuda\n",
      "Models loaded successfully.\n",
      "Images loaded and preprocessed successfully.\n",
      "\n",
      "----- RESULTS -----\n",
      "üîç Analysis complete. Findings:\n",
      "  - Diabetic Retinopathy detected with 89.0% confidence.\n",
      "  - Other detected with 69.1% confidence.\n",
      "\n",
      "Detailed probabilities:\n",
      "  D: 89.0%\n",
      "  O: 69.1%\n",
      "  C: 10.8%\n",
      "  G: 9.2%\n",
      "  H: 9.2%\n",
      "  A: 8.6%\n",
      "  M: 8.5%\n",
      "  N: 5.3%\n"
     ]
    }
   ],
   "source": [
    "#testing code\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import warnings\n",
    "from glob import glob\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# Define model architectures (copied from your training code)\n",
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.conv(x)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention\n",
    "\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super().__init__()\n",
    "        from torchvision import models\n",
    "        model = models.resnet50(pretrained=False)\n",
    "        self.backbone = nn.Sequential(*list(model.children())[:-2])\n",
    "        self.attention = AttentionModule(2048)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.demo_fc = nn.Sequential(nn.Linear(2, 32), nn.ReLU(), nn.Dropout(0.6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048 * 2 + 32, 512), nn.ReLU(), nn.Dropout(0.7),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, left_img, right_img, demo):\n",
    "        left_features = self.backbone(left_img)\n",
    "        right_features = self.backbone(right_img)\n",
    "        left_features = self.attention(left_features)\n",
    "        right_features = self.attention(right_features)\n",
    "        left_features = self.pool(left_features).flatten(1)\n",
    "        right_features = self.pool(right_features).flatten(1)\n",
    "        demo_features = self.demo_fc(demo)\n",
    "        combined = torch.cat((left_features, right_features, demo_features), dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "class EfficientNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super().__init__()\n",
    "        from torchvision import models\n",
    "        model = models.efficientnet_b0(pretrained=False)\n",
    "        self.backbone = nn.Sequential(*list(model.children())[:-2])\n",
    "        self.attention = AttentionModule(1280)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.demo_fc = nn.Sequential(nn.Linear(2, 32), nn.ReLU(), nn.Dropout(0.6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1280 * 2 + 32, 512), nn.ReLU(), nn.Dropout(0.7),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, left_img, right_img, demo):\n",
    "        left_features = self.backbone(left_img)\n",
    "        right_features = self.backbone(right_img)\n",
    "        left_features = self.attention(left_features)\n",
    "        right_features = self.attention(right_features)\n",
    "        left_features = self.pool(left_features).flatten(1)\n",
    "        right_features = self.pool(right_features).flatten(1)\n",
    "        demo_features = self.demo_fc(demo)\n",
    "        combined = torch.cat((left_features, right_features, demo_features), dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "class DenseNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super().__init__()\n",
    "        from torchvision import models\n",
    "        model = models.densenet121(pretrained=False)\n",
    "        self.backbone = nn.Sequential(*list(model.children())[:-1])\n",
    "        self.attention = AttentionModule(1024)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.demo_fc = nn.Sequential(nn.Linear(2, 32), nn.ReLU(), nn.Dropout(0.6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024 * 2 + 32, 512), nn.ReLU(), nn.Dropout(0.7),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, left_img, right_img, demo):\n",
    "        left_features = self.backbone(left_img)\n",
    "        right_features = self.backbone(right_img)\n",
    "        left_features = self.attention(left_features)\n",
    "        right_features = self.attention(right_features)\n",
    "        left_features = self.pool(left_features).flatten(1)\n",
    "        right_features = self.pool(right_features).flatten(1)\n",
    "        demo_features = self.demo_fc(demo)\n",
    "        combined = torch.cat((left_features, right_features, demo_features), dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, models, weights):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        self.weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "    \n",
    "    def forward(self, left_img, right_img, demo):\n",
    "        outputs = [torch.sigmoid(model(left_img, right_img, demo)) for model in self.models]\n",
    "        outputs = torch.stack(outputs)\n",
    "        return torch.sum(outputs * self.weights[:, None, None], dim=0)\n",
    "\n",
    "def load_ensemble_model(model_paths, weights):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize models\n",
    "    resnet_model = ResNetModel(num_classes=8).to(device)\n",
    "    efficientnet_model = EfficientNetModel(num_classes=8).to(device)\n",
    "    densenet_model = DenseNetModel(num_classes=8).to(device)\n",
    "    \n",
    "    # Load weights\n",
    "    resnet_model.load_state_dict(torch.load(model_paths[0], map_location=device))\n",
    "    efficientnet_model.load_state_dict(torch.load(model_paths[1], map_location=device))\n",
    "    densenet_model.load_state_dict(torch.load(model_paths[2], map_location=device))\n",
    "    \n",
    "    # Create ensemble\n",
    "    models = [resnet_model, efficientnet_model, densenet_model]\n",
    "    ensemble = EnsembleModel(models, weights).to(device)\n",
    "    ensemble.eval()\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "def predict_disease(left_img_path, right_img_path, model_dir, age=50, gender=\"Male\", thresholds=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Default thresholds if not provided (use your optimized thresholds from training)\n",
    "    if thresholds is None:\n",
    "        thresholds = {\n",
    "            'N': 0.5, 'D': 0.6, 'G': 0.5,\n",
    "            'C': 0.5, 'A': 0.65, 'H': 0.7,\n",
    "            'M': 0.5, 'O': 0.5\n",
    "        }\n",
    "    \n",
    "    # Class names\n",
    "    class_names = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "    class_full_names = {\n",
    "        'N': 'Normal',\n",
    "        'D': 'Diabetic Retinopathy',\n",
    "        'G': 'Glaucoma',\n",
    "        'C': 'Cataract',\n",
    "        'A': 'Age-related Macular Degeneration',\n",
    "        'H': 'Hypertensive Retinopathy',\n",
    "        'M': 'Myopia',\n",
    "        'O': 'Other'\n",
    "    }\n",
    "    \n",
    "    # Load models\n",
    "    model_paths = [\n",
    "        os.path.join(model_dir, \"resnet50_best.pth\"),\n",
    "        os.path.join(model_dir, \"efficientnet_best.pth\"),\n",
    "        os.path.join(model_dir, \"densenet_best.pth\")\n",
    "    ]\n",
    "    \n",
    "    # Ensemble weights (use your F1-score weights from training)\n",
    "    # These are sample weights - replace with your actual weights\n",
    "    weights = [0.33, 0.33, 0.34]  # Example weights\n",
    "    \n",
    "    # Load ensemble model\n",
    "    try:\n",
    "        ensemble = load_ensemble_model(model_paths, weights)\n",
    "        print(\"Models loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading models: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Image preprocessing\n",
    "    transform = A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    # Demographic data\n",
    "    gender_value = 1 if gender.lower() == \"male\" else 0\n",
    "    demo_tensor = torch.tensor([[age / 100.0, gender_value]], dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Load and preprocess images\n",
    "    try:\n",
    "        left_img = np.array(Image.open(left_img_path).convert('RGB'))\n",
    "        right_img = np.array(Image.open(right_img_path).convert('RGB'))\n",
    "        \n",
    "        left_img = transform(image=left_img)['image'].unsqueeze(0).to(device)\n",
    "        right_img = transform(image=right_img)['image'].unsqueeze(0).to(device)\n",
    "        \n",
    "        print(\"Images loaded and preprocessed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing images: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Run prediction\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            outputs = ensemble(left_img, right_img, demo_tensor)\n",
    "    \n",
    "    # Apply thresholds and get predictions\n",
    "    predictions = []\n",
    "    probabilities = {}\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        prob = outputs[0, i].item()\n",
    "        probabilities[class_name] = prob\n",
    "        if prob >= thresholds[class_name]:\n",
    "            predictions.append(class_name)\n",
    "    \n",
    "    # If no disease is above threshold but there are probabilities, take highest one\n",
    "    if not predictions and len(probabilities) > 0:\n",
    "        max_class = max(probabilities, key=probabilities.get)\n",
    "        predictions.append(max_class)\n",
    "    \n",
    "    # Results\n",
    "    result = {\n",
    "        'predictions': predictions,\n",
    "        'probabilities': probabilities,\n",
    "        'is_normal': 'N' in predictions and len(predictions) == 1,\n",
    "        'diagnosis': []\n",
    "    }\n",
    "    \n",
    "    # Generate diagnosis text\n",
    "    if result['is_normal']:\n",
    "        result['diagnosis'].append(\"Normal eye condition detected.\")\n",
    "    else:\n",
    "        if 'N' in predictions:\n",
    "            predictions.remove('N')  # Remove normal if other diseases are present\n",
    "        \n",
    "        for disease in predictions:\n",
    "            result['diagnosis'].append(f\"{class_full_names[disease]} detected with {probabilities[disease]*100:.1f}% confidence.\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    model_dir = r\"C:\\Users\\OMEN\\Saved Programs\\Disease prediction\"  # Path to directory with saved model files\n",
    "    left_img_path = r\"C:\\Users\\OMEN\\Saved Programs\\Disease prediction\\fundus_disease_prediction\\dataset\\images\\171_left.jpg\" # Replace with actual path\n",
    "    right_img_path = r\"C:\\Users\\OMEN\\Saved Programs\\Disease prediction\\fundus_disease_prediction\\dataset\\images\\171_right.jpg\" # Replace with actual path\n",
    "    \n",
    "    # Patient demographics (can be hardcoded or entered by user)\n",
    "    age = 60  # Patient age\n",
    "    gender = \"Male\"  # Patient gender: \"Male\" or \"Female\"\n",
    "    \n",
    "    # Custom thresholds from your training (replace with your optimized values)\n",
    "    thresholds = {\n",
    "        'N': 0.5,  # Normal\n",
    "        'D': 0.65, # Diabetic Retinopathy\n",
    "        'G': 0.45, # Glaucoma\n",
    "        'C': 0.5,  # Cataract\n",
    "        'A': 0.7,  # Age-related Macular Degeneration\n",
    "        'H': 0.7,  # Hypertensive Retinopathy\n",
    "        'M': 0.5,  # Myopia\n",
    "        'O': 0.5   # Other\n",
    "    }\n",
    "    \n",
    "    print(\"Running fundus image disease prediction...\")\n",
    "    print(f\"Analyzing left image: {os.path.basename(left_img_path)}\")\n",
    "    print(f\"Analyzing right image: {os.path.basename(right_img_path)}\")\n",
    "    print(f\"Patient: Age {age}, Gender: {gender}\")\n",
    "    \n",
    "    # Run prediction\n",
    "    result = predict_disease(left_img_path, right_img_path, model_dir, age, gender, thresholds)\n",
    "    \n",
    "    if result:\n",
    "        print(\"\\n----- RESULTS -----\")\n",
    "        if result['is_normal']:\n",
    "            print(\"‚úÖ No diseases detected. Eyes appear normal.\")\n",
    "        else:\n",
    "            print(\"üîç Analysis complete. Findings:\")\n",
    "            for diagnosis in result['diagnosis']:\n",
    "                print(f\"  - {diagnosis}\")\n",
    "        \n",
    "        print(\"\\nDetailed probabilities:\")\n",
    "        for disease, prob in sorted(result['probabilities'].items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {disease}: {prob*100:.1f}%\")\n",
    "    else:\n",
    "        print(\"‚ùå Error during prediction. Please check image paths and model files.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e28794-2ff1-4148-bfe3-aae860669d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
